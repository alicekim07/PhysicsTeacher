import os
import base64
import json
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI()

# í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """
    You are a researcher giving an invited conference talk.

    You are speaking to chemists and physicists who have working knowledge
    of spectroscopy and interfacial science, but are not familiar with
    sum-frequency spectroscopy.

    This is NOT a lecture for students.
    This is a scientific presentation to professional peers.

    Your role:
    - Speak as an active researcher presenting your own work.
    - Guide the audience through the talk slide by slide.
    - Respect the logical and temporal order of the presentation.

    CRITICAL RULE:
    Each slide has strict metadata defining what is allowed and forbidden.
    You MUST follow the slide metadata exactly.
    Mentioning any forbidden content is considered a failure.

    ğŸ”§ STAGE-DEPENDENT HARD CONSTRAINTS:
    - If the slide stage is INTRO or METHOD:
    - You MUST NOT describe results, trends, signal changes,
        unexpected behavior, or conclusions,
        even in general or qualitative terms.
    - Words such as "unexpected", "anomalous", "increase", "decrease",
    or any implication of outcome are forbidden unless explicitly allowed.

    Your goals for each slide:
    - Explain only what this slide is intended to establish.
    - Help the audience understand why this slide exists at this point
    in the talk.
    - Do NOT anticipate results, surprises, or conclusions from later slides
    unless explicitly allowed.

    Style requirements:
    - Speak naturally, as in a live conference presentation.
    - Do not sound like a textbook or a review article.
    - Do not over-explain concepts the audience is assumed to know.

    Technical language:
    - Use standard scientific terminology common in spectroscopy.
    - Avoid equations and formal derivations.
    - Focus on physical intuition and experimental logic.

    Important constraints:
    - Do NOT invent data, mechanisms, or conclusions.
    - Do NOT summarize the entire talk in one slide.
    - Treat each slide as a fixed temporal boundary.

    This script will be used for AI-generated voice narration.
    Write in clear, spoken English suitable for a live scientific talk.
"""

USER_PROMPT = """
    Based on the slide content and the slide metadata provided,
    write a spoken script as if you are presenting this slide
    at a scientific conference.

    Guidelines:
    - Focus on what the audience should notice in THIS slide.
    - Explain why this slide is needed at this point in the talk.
    - Describe something as surprising or counterintuitive
    ONLY if the slide metadata explicitly allows it.

    Do not:
    - Read the slide text verbatim.
    - Turn the explanation into a classroom lecture.
    - Add background, results, or conclusions belonging to other slides.

    Maintain a natural speaking rhythm appropriate for a live talk.
"""

OCR_SYSTEM = """
    ë„ˆëŠ” ëŒ€í•™êµ ê°•ì˜ ìŠ¬ë¼ì´ë“œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ë„êµ¬ë‹¤.
    ë„ˆì˜ ëª©í‘œëŠ” 'ë³´ì´ëŠ” ê¸€ì'ë¥¼ ìµœëŒ€í•œ ì •í™•íˆ ì˜®ê¸°ëŠ” ê²ƒì´ë‹¤.

    ê·œì¹™:
    - ì ˆëŒ€ ë‚´ìš©ì„ í•´ì„í•˜ê±°ë‚˜ ì„¤ëª…í•˜ì§€ ë§ê³ , ë³´ì´ëŠ” í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•´ë¼.
    - ì œëª©, ì†Œì œëª©, ë³¸ë¬¸, ë¶ˆë¦¿, ìº¡ì…˜ì„ êµ¬ë¶„í•´ë¼.
    - ìˆ˜ì‹/ê¸°í˜¸ê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë¬¸ìì—´ë¡œ í¬í•¨í•˜ë˜, ë”°ë¡œ equations ë°°ì—´ì—ë„ ë„£ì–´ë¼.
    - ì˜ ì•ˆ ë³´ì´ëŠ” ê²½ìš° confidenceë¥¼ ë‚®ê²Œ ì£¼ê³ , uncertain_tokensì— í›„ë³´ë¥¼ ê¸°ë¡í•´ë¼.
    - ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ.
"""

OCR_USER = """
    ì´ ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•´ JSONìœ¼ë¡œ ë°˜í™˜í•´ë¼.
"""

SEMANTIC_SYSTEM_PROMPT = """
    ë„ˆëŠ” ëŒ€í•™êµ ë¬¼ë¦¬ ê°•ì˜ ìŠ¬ë¼ì´ë“œë¥¼ í•´ì„í•˜ëŠ” ì¡°êµë‹¤.

    ì…ë ¥ì€ OCRë¡œ ì¶”ì¶œëœ ìŠ¬ë¼ì´ë“œ í…ìŠ¤íŠ¸ì™€ ìˆ˜ì‹ ëª©ë¡ì´ë‹¤.

    ë„ˆì˜ ì—­í• ì€:
    - ì´ ìŠ¬ë¼ì´ë“œì—ì„œ êµìˆ˜ìê°€ ì „ë‹¬í•˜ë ¤ëŠ” í•µì‹¬ ê°œë…ì„ ì¶”ì¶œí•˜ëŠ” ê²ƒ
    - êµìˆ˜ì˜ ë§ì´ë‚˜ ì„¤ëª… ë¬¸ì¥ì„ ì‘ì„±í•˜ì§€ ì•Šê³ , êµìˆ˜ìê°€ ë¨¸ë¦¬ì†ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê°œë…ì  êµ¬ì¡°ë§Œ ì •ë¦¬í•˜ëŠ” ê²ƒ

    ì—„ê²©í•œ ê¸ˆì§€ ê·œì¹™ :
    - ìˆ˜í•™ ê¸°í˜¸, ê¸°í˜¸ ì´ë¦„, ì•ŒíŒŒë²³ ë¬¼ë¦¬ëŸ‰ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ
    - ê³„ì‚° ì ˆì°¨, ë‹¨ê³„ ë‚˜ì—´, ê³µì‹ ì†Œê°œë¥¼ í¬í•¨í•˜ì§€ ë§ ê²ƒ
    - "ì„¤ëª…í•œë‹¤", "ë³´ì—¬ì¤€ë‹¤", "ë…¼ì˜í•œë‹¤", "ë‹¨ê³„ë³„ë¡œ", "ê³¼ì •"ê³¼ ê°™ì€ ì„¤ëª…í˜• ë™ì‚¬ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ
    - êµê³¼ì„œ ìš”ì•½ì²˜ëŸ¼ ë³´ì´ëŠ” ì„œìˆ ì„ í•˜ì§€ ë§ ê²ƒ
    
    ì¶œë ¥ ë‚´ìš© ì§€ì¹¨:
    - í•µì‹¬ ê°œë… í•˜ë‚˜ë¥¼ ì¤‘ì‹¬ ê°œë…ìœ¼ë¡œ ì œì‹œí•  ê²ƒ
    - ê·¸ ê°œë…ì„ ì´í•´í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ê°œë…ì  ê´€ê³„ë“¤ì„ ì—¬ëŸ¬ ê°œì˜ **ê°œë… í¬ì¸íŠ¸**ë¡œ ë‚˜ëˆ„ì–´ ì •ë¦¬í•  ê²ƒ
    - ê° ê°œë… í¬ì¸íŠ¸ëŠ” 'ë¬´ì—‡ê³¼ ë¬´ì—‡ì´ ì–´ë–¤ ê´€ê³„ì— ìˆëŠ”ê°€'ë¥¼ ë“œëŸ¬ë‚´ëŠ” ê°œë… ìˆ˜ì¤€ì˜ ì§„ìˆ ì´ì–´ì•¼ í•œë‹¤.
    - ë§í•˜ë“¯ ì„¤ëª…í•˜ì§€ ë§ê³ , ê°œë… ì§€ë„ì²˜ëŸ¼ ì •ë¦¬í•  ê²ƒ

    ì¶œë ¥ í˜•ì‹ ê·œì¹™ (ë§¤ìš° ì¤‘ìš”):
    - ì¶œë ¥ì€ ë°˜ë“œì‹œ **ìˆœìˆ˜ JSON ê°ì²´ í•˜ë‚˜ë§Œ** ë°˜í™˜í•´ë¼
    - ì¶œë ¥ì˜ ì²« ê¸€ìëŠ” { ì´ê³  ë§ˆì§€ë§‰ ê¸€ìëŠ” } ì—¬ì•¼ í•œë‹¤
    - JSON ì•ë’¤ì— ì–´ë– í•œ ì„¤ëª…, ì¸ì‚¬, ë¬¸ì¥ë„ ë¶™ì´ì§€ ë§ˆë¼
    - ì½”ë“œë¸”ë¡(''')ì„ ì‚¬ìš©í•˜ì§€ ë§ˆë¼
"""

SEMANTIC_USER_PROMPT = """
    ë‹¤ìŒì€ í•œ ì¥ì˜ ëŒ€í•™êµ ë¬¼ë¦¬í•™ ê°•ì˜ ìŠ¬ë¼ì´ë“œì—ì„œ OCRë¡œ ì¶”ì¶œëœ ì •ë³´ë‹¤.

    ì´ ìŠ¬ë¼ì´ë“œì—ì„œ êµìˆ˜ê°€ í•™ìƒì—ê²Œ ì „ë‹¬í•˜ë ¤ëŠ” í•µì‹¬ ê°œë…ê³¼ ê·¸ ê°œë…ì„ êµ¬ì„±í•˜ëŠ” ê°œë…ì  ê´€ê³„ë¥¼ JSONìœ¼ë¡œ ì •ë¦¬í•´ë¼.
"""

ALIGN_SYSTEM_PROMPT = """
    ë„ˆëŠ” ê°•ì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ì—­í• ì´ ì•„ë‹ˆë‹¤.

    ë„ˆì˜ ì—­í• ì€:
    - ìŠ¬ë¼ì´ë“œì˜ í•µì‹¬ ê°œë…(WHAT)ê³¼
    - êµìˆ˜ì˜ ê°•ì˜ ìŠ¤íƒ€ì¼(HOW)ì„ ì°¸ê³ í•˜ì—¬
    - ìŠ¤í¬ë¦½íŠ¸ ìƒì„±ê¸°ê°€ ë”°ë¼ì•¼ í•  'ì„¤ëª… ì§€ì¹¨'ì„ ë§Œë“œëŠ” ê²ƒì´ë‹¤.

    ì¤‘ìš” ê·œì¹™:
    - ì‹¤ì œ ê°•ì˜ ë¬¸ì¥ì´ë‚˜ ì„¤ëª… ë¬¸ë‹¨ì„ ì ˆëŒ€ ì‘ì„±í•˜ì§€ ë§ˆë¼
    - êµì¬ì²˜ëŸ¼ ì„œìˆ í•˜ì§€ ë§ˆë¼
    - ìƒˆë¡œìš´ ë¬¼ë¦¬ ê°œë…ì„ ì¶”ê°€í•˜ì§€ ë§ˆë¼
    - ìŠ¬ë¼ì´ë“œì— ì—†ëŠ” ë‚´ìš©ì„ í™•ì¥í•˜ì§€ ë§ˆë¼

    ì¶œë ¥ í˜•ì‹ ê·œì¹™ (ë§¤ìš° ì¤‘ìš”):
    - ì¶œë ¥ì€ ë°˜ë“œì‹œ **ìˆœìˆ˜ JSON ê°ì²´ í•˜ë‚˜ë§Œ** ë°˜í™˜í•´ë¼
    - ì¶œë ¥ì˜ ì²« ê¸€ìëŠ” { ì´ê³  ë§ˆì§€ë§‰ ê¸€ìëŠ” } ì—¬ì•¼ í•œë‹¤
    - JSON ì•ë’¤ì— ì–´ë– í•œ ì„¤ëª…, ì¸ì‚¬, ë¬¸ì¥ë„ ë¶™ì´ì§€ ë§ˆë¼
    - ì½”ë“œë¸”ë¡(''')ì„ ì‚¬ìš©í•˜ì§€ ë§ˆë¼
    - JSON êµ¬ì¡°ëŠ” ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥¼ ê²ƒ

    {
        "instruction": "ì´ ìŠ¬ë¼ì´ë“œë¥¼ ì„¤ëª…í•  ë•Œì˜ ì „ì²´ ë°©í–¥ í•œ ë¬¸ì¥",
        "emphasis":  ["ë°˜ë“œì‹œ ê°•ì¡°í•´ì•¼ í•  ê°œë… í¬ì¸íŠ¸ë“¤"],
        "avoid": ["ì„¤ëª…ì—ì„œ í”¼í•´ì•¼ í•  ë°©ì‹ì´ë‚˜ í‘œí˜„ë“¤"]
    }
"""

ALIGN_USER_PROMPT = """
    ë‹¤ìŒì€ í•œ ì¥ì˜ ê°•ì˜ ìŠ¬ë¼ì´ë“œì— ëŒ€í•œ ì •ë³´ë‹¤.

    - slide_semantics: ì´ ìŠ¬ë¼ì´ë“œì—ì„œ ë¬´ì—‡ì„ ì„¤ëª…í•´ì•¼ í•˜ëŠ”ì§€ ì •ë¦¬ëœ ì •ë³´
    - professor_style: êµìˆ˜ì˜ ê°•ì˜ ìŠ¤íƒ€ì¼ ìš”ì•½

    ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ìŠ¤í¬ë¦½íŠ¸ ìƒì„±ê¸°ê°€ ë”°ë¼ì•¼ í•  ì„¤ëª… ì§€ì¹¨ì„ ë§Œë“¤ì–´ë¼.
"""

# Helper í•¨ìˆ˜
def encode_image_to_data_url(path):
    with open(path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode("utf-8")
    return f"data:image/png;base64,{b64}"

def _debug_print_json(obj, max_len=5000):
    import json
    s = json.dumps(obj, ensure_ascii=False, indent=2)
    print(s[:max_len] + ("..." if len(s) > max_len else ""))

def summarize_for_context(script_text):
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """
                    You are preparing a brief context reminder
                    for the next slide in a scientific presentation.

                    Summarize only what has already been explicitly stated,
                    focusing on factual content, not interpretation.

                    Rules:
                    - Do NOT explain why the content is important.
                    - Do NOT describe implications, significance, or conclusions.
                    - Do NOT introduce expectations or future results.
                    - Do NOT use evaluative language (e.g., surprising, important, interesting).
                    - Do NOT use equations, symbols, or abbreviations.

                    Write in neutral, descriptive language.
                    Remove conversational fillers.
                    Limit the summary to two or three short sentences.
                """

            },
            {
                "role": "user",
                "content": script_text
            }
        ],
        temperature=0.2
    )
    return response.choices[0].message.content.strip()

# 1. OCR ì¶”ì¶œ
def extract_text_from_image(slide_path: str, model: str = "gpt-4o", temperature: float = 0.0) -> dict:
    """
    Slide image -> structured OCR-like text extraction
    Returns dict with fields:
    - title: str
    - headings: list[str]
    - bullets: list[str]
    - body: str
    - captions: list[str]
    - equations: list[str]
    - confidence: float (0~1)
    - uncertain_tokens: list[str]
    """
    image_data_url = encode_image_to_data_url(slide_path)

    resp = client.chat.completions.create(
        model=model,
        temperature=temperature,
        messages=[
            {"role": "system", "content": OCR_SYSTEM},
            {"role": "user", "content": [
                {"type": "text", "text": OCR_USER},
                {"type": "image_url", "image_url": {"url": image_data_url}}
            ]}
        ],
    )

    text = resp.choices[0].message.content.strip()

    try:
        data = json.loads(text)
    except json.JSONDecodeError:
        # ëª¨ë¸ì´ JSON ë°– í…ìŠ¤íŠ¸ë¥¼ ì„ìœ¼ë©´, ìµœì†Œ ë³µêµ¬ ì‹œë„
        start = text.find("{")
        end = text.rfind("}")
        if start != -1 and end != -1 and end > start:
            data = json.loads(text[start:end+1])
        else:
            raise ValueError("OCR output is not valid JSON")
        
    return data

# 2. Semantic Extractor Agent ì¶”ê°€
def extract_slide_semantics(ocr: dict) -> dict:
    resp = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.2,
        messages=[
            {
                "role": "system",
                "content": SEMANTIC_SYSTEM_PROMPT
            },
            {
                "role": "user",
                "content": (
                    SEMANTIC_USER_PROMPT
                    + "\n\n[OCR RESULT]\n"
                    + json.dumps(ocr, ensure_ascii=False, indent=2)
                )
            }
        ]
    )

    text = resp.choices[0].message.content.strip()

    try:
        return json.loads(text)
    except json.JSONDecodeError:
        return {
            "raw_text": ocr,
            "summary": text,
            "note": "fallback semantic extraction"
        }

# 3. Context Alignment Agent
def align_contexts(slide_semantics: dict, professor_style: dict) -> dict:
    resp = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.2,
        messages=[
            {
                "role": "system",
                "content": ALIGN_SYSTEM_PROMPT
            },
            {
                "role": "user",
                "content": (
                    ALIGN_USER_PROMPT
                    + "\n\n"
                    + json.dumps(
                        {
                            "slide_semantics": slide_semantics,
                            "professor_style": professor_style
                        },
                        ensure_ascii=False,
                        indent=2
                    )
                )
            }
        ]
    )

    text = resp.choices[0].message.content.strip()
    return json.loads(text)

# 4. Script Generator
def generate_script(
    slide_semantics: dict,
    alignment: dict,
    previous_context: str,
    slide_index: int,
    total_slides: int,
    slide_metadata: dict | None = None
):
    """
    Generate lecture script from:
    - slide_semantics: ë¬´ì—‡ì„ ì„¤ëª…í• ì§€
    - alignment: ì–´ë–»ê²Œ ì„¤ëª…í• ì§€
    - previous_context: ì• ìŠ¬ë¼ì´ë“œ ìš”ì•½
    """

    # 1. ìŠ¬ë¼ì´ë“œ Metadata ë¸”ë¡
    metadata_block = f"""
    [Slide role and constraints]
    - Presentation stage: {slide_metadata.get("stage")}

    - Purpose of this slide:
    {slide_metadata.get("intent")}

    - Strict constraints for this slide:
    {chr(10).join("- " + f for f in slide_metadata.get("forbidden", []))}

    You must strictly follow these constraints.
    Do not mention topics that are forbidden at this stage,
    even if they appear related to the slide content.
    """

    # 2. Alignment ê·œì¹™ ë¸”ë¡
    alignment_block = f"""
    [ì„¤ëª… ì§€ì¹¨]
    - ì „ì²´ ì„¤ëª… ë°©í–¥
    {alignment.get("instruction", "")}

    - ë°˜ë“œì‹œ ê°•ì¡°í•  ê°œë…
    {chr(10).join("- " + e for e in alignment.get("emphasis", []))}

    - ë°˜ë“œì‹œ í”¼í•  ì„¤ëª… ë°©ì‹:
    {chr(10).join("- " + a for a in alignment.get("avoid", []))}

    ìœ„ ì§€ì¹¨ì„ ë°˜ë“œì‹œ ë”°ë¥¼ ê²ƒ.
    """

    # 3. ê°•ì˜ íë¦„ ì§€ì¹¨
    if slide_index == 0:
        flow_block = """
            This is the opening slide of the talk.

            Begin by setting the context of the problem or system,
            without introducing results or conclusions.

            Speak at a measured pace, as the audience is still orienting
            to the topic and terminology.

            End the slide by pointing to the aspect of the system
            that will be examined next, without answering it.
        """

    elif slide_index < total_slides - 1:
        flow_block = """
            This slide is part of the main body of the talk.

            Continue naturally from the previous slide,
            without reintroducing the topic or restating the motivation.

            Focus on explaining what is shown on this slide,
            and stop once the intended point has been made.

            Do not conclude, summarize, or preview later results.
        """

    else:
        flow_block = """
            This is the final slide of the talk.

            Speak calmly and deliberately.

            Indicate how the content of this slide fits into
            the overall narrative of the presentation,
            without introducing new interpretations or future directions.

            End without signaling the end of the talk explicitly.
        """


    # 4. ì´ì „ ìŠ¬ë¼ì´ë“œ ì—°ê²°
    previous_block = ""
    if previous_context:
        previous_block = f"""
            [ì• ìŠ¬ë¼ì´ë“œì—ì„œ ì´ë¯¸ ì„¤ëª…í•œ ë‚´ìš© ìš”ì•½]
            {previous_context}
        """

    # 5. ìŠ¬ë¼ì´ë“œ ì˜ë¯¸ ì •ë³´
    semantic_block = f"""
        [ì´ë²ˆ ìŠ¬ë¼ì´ë“œ í•µì‹¬ ê°œë… ìš”ì•½]
        {json.dumps(slide_semantics, ensure_ascii=False, indent=2)}
    """

    # 6. ë©”ì‹œì§€ êµ¬ì„±
    messages = [
        {
            "role": "system",
            "content": SYSTEM_PROMPT
        },
        {
            "role": "assistant",
            "content": (
                metadata_block
                + "\n"
                + alignment_block
                + "\n"
                + flow_block
                + "\n"
                + previous_block
            )
        },
        {
            "role": "user",
            "content": (
                USER_PROMPT
                + "\n\n"
                + semantic_block
            )
        }
    ]

    # 7. LLM í˜¸ì¶œ
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.4
    )

    return response.choices[0].message.content.strip()

# 5. Pipeline
def slides_to_scripts(slides_dir: str, scripts_dir: str, professor_style: dict, slide_metadata_map : dict):
    slides = sorted(f for f in os.listdir(slides_dir) if f.endswith(".png"))
    total_slides = len(slides)

    previous_context = ""

    for idx, slide in enumerate(slides):
        slide_path = os.path.join(slides_dir, slide)

        # 1) OCR
        ocr = extract_text_from_image(slide_path)
 
        # 2) Semantics
        sem = extract_slide_semantics(ocr)

        # 3) Alignment (sem + professor_style)
        alignment = align_contexts(sem, professor_style)

        # 4) Script
        current_metadata = slide_metadata_map.get(slide)
        if current_metadata is None:
            raise ValueError(f"Slide metadata not found for {slide}")

        script_text = generate_script(
            slide_semantics=sem,
            alignment=alignment,
            previous_context=previous_context,
            slide_index=idx,
            total_slides=total_slides,
            slide_metadata=current_metadata
        )

        # 5) Save script
        script_name = slide.replace(".png", ".txt")
        script_path = os.path.join(scripts_dir, script_name)

        with open(script_path, "w", encoding="utf-8") as f:
            f.write(script_text)

        previous_context = summarize_for_context(script_text)
        print(f"[script] {script_name} ìƒì„± ì™„ë£Œ")

if __name__ == "__main__":
    test_slide_path = "../slide_09.png"

    professor_style = {"tone": "casual and enthusiastic", "explanation_style": "informal", "engagement": "uses humor and enthusiasm to engage students", "repetition": "repeats phrases to emphasize enjoyment", "language": "uses simple and relatable language"}

    print("\n=== [OCR] ===")
    ocr = extract_text_from_image(test_slide_path)
    _debug_print_json(ocr, max_len=2000)

    print("\n=== [SEMANTIC] ===")
    sem = extract_slide_semantics(ocr)
    _debug_print_json(sem, max_len=2000)

    print("\n=== [ALIGNMENT] ===")
    alignment = align_contexts(sem, professor_style)
    _debug_print_json(alignment, max_len=2000)

    print("\n=== [SCRIPT] ===")
    script = generate_script(
        slide_semantics=sem,
        alignment=alignment,
        previous_context="", # ì²« ìŠ¬ë¼ì´ë“œë¼ê³  ê°€ì •
        slide_index=0,
        total_slides=10
    )
    print(script)